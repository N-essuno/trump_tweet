{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:00:48.485547800Z",
     "start_time": "2024-03-07T16:00:48.451548200Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from typing import List, Tuple, Optional, Set\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the data and retrieve tweets tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a930147827f7723"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we need to clean the data: let's remove the `\"` character from the tweets because some of them have it at the start of the tweet but miss it at the end. This will cause the dataframe tweet column to be mixed with the following columns."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f370ae307a3b6f78"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('resources/tweets.csv', 'r', encoding=\"utf8\") as f:\n",
    "    tweets = f.readlines()\n",
    "    tweets = [tweet.replace('\"', '') for tweet in tweets]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:00:48.514586700Z",
     "start_time": "2024-03-07T16:00:48.458545700Z"
    }
   },
   "id": "a4854a5eac1365f6",
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can retrieve the tweets tokens. We will use the `word_tokenize` function from the `nltk.tokenize` module to tokenize the tweets.\n",
    "We also add the start and end tokens to each tweet and merge all tokens into one list."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c69a473a202a4306"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LOSER', '!', 'https', ':', '//t.co/p5imhMJqS1']\n",
      "['<s>', 'LOSER', '!', 'https', ':', '//t.co/p5imhMJqS1', '</s>', '<s>', 'Most', 'of', 'the', 'money', 'raised', 'by', 'the']\n"
     ]
    }
   ],
   "source": [
    "# split csv data columns and select the one with tweet texts\n",
    "tweet_texts = [tweet.split(\",\")[1] for tweet in tweets[1:]]\n",
    "\n",
    "# tokenize each tweet, the result is a list of lists where each inner list (list of strings) contains the tokens (single words) of a tweet.\n",
    "tweets_tokens = [word_tokenize(tweet) for tweet in tweet_texts]\n",
    "print(tweets_tokens[0])\n",
    "\n",
    "# add start and end tokens to each tweet\n",
    "tweets_tokens = [['<s>'] + tweet + ['</s>'] for tweet in tweets_tokens]\n",
    "\n",
    "# merge all tokens into one list of strings\n",
    "tokens = [token for tweet in tweets_tokens for token in tweet]\n",
    "print(tokens[0:15])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:00:48.536549Z",
     "start_time": "2024-03-07T16:00:48.475548300Z"
    }
   },
   "id": "b82b1f3ee6df8b6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Generate n-grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e730e8b83e26fcf"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "bigrams = list(ngrams(tokens, 2))\n",
    "trigrams = list(ngrams(tokens,3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:00:48.581165Z",
     "start_time": "2024-03-07T16:00:48.537564200Z"
    }
   },
   "id": "305d6fd730cc1b7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Count n-grams frequencies\n",
    "\n",
    "For each n-gram we use the `Counter` class from the `collections` module to count the frequency of each n-gram.\n",
    "Each n-gram is stored in a dictionary where the key is the n-gram and the value is its the frequency."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "242ff5fd249f90c4"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram 0: ('<s>', 'LOSER') - Frequency: 1\n",
      "Bigram 1: ('LOSER', '!') - Frequency: 2\n",
      "Bigram 2: ('!', 'https') - Frequency: 10\n"
     ]
    }
   ],
   "source": [
    "bigrams_freq = Counter(bigrams)\n",
    "trigrams_freq = Counter(trigrams)\n",
    "for i in range(3):\n",
    "    print(f\"Bigram {i}: {bigrams[i]} - Frequency: {bigrams_freq[bigrams[i]]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:00:48.588158300Z",
     "start_time": "2024-03-07T16:00:48.553552100Z"
    }
   },
   "id": "b4df8f394825f916"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Generate tweets\n",
    "\n",
    "We generate tweets using the bigrams and trigrams frequencies. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28e8f453c9406b47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we have the list of tokens for each tweet, we can join them in a human natural way (eg. avoid spacing before punctuation mark and after a @ or a # symbol)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2391b3a0d4baee89"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "punctuation: Set = {\".\", \",\", \"!\", \"?\", \")\", \"]\", \"}\", \":\", \";\", \"'\", \"\\\"\", \"’\", \"‘\",\n",
    "               \"”\", \"–\", \"—\", \"…\", \"•\", \"·\", \"``\", \"''\", \"'\"}\n",
    "\n",
    "def join_tokens(tweet_tokens: List[str]) -> str:\n",
    "    tweet_text:str = \"\"\n",
    "    skip_space = False\n",
    "    for token in tweet_tokens:\n",
    "        if token in punctuation:\n",
    "            tweet_text = tweet_text + token\n",
    "        elif token in (\"@\", \"(\", \"#\", \"“\"):\n",
    "            tweet_text += \" \" + token\n",
    "            skip_space = True\n",
    "        else:\n",
    "            if skip_space:\n",
    "                tweet_text += token\n",
    "                skip_space = False\n",
    "            else:\n",
    "                tweet_text += \" \" + token\n",
    "    return tweet_text.replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:00:48.589157400Z",
     "start_time": "2024-03-07T16:00:48.568605700Z"
    }
   },
   "id": "f41d6bcc896dddef",
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "source": [
    "To generate tweets from bigrams the following choices are made:\n",
    "- If the start word is not provided, the first word will be the start token.\n",
    "- If a token that is never followed by another token (other than the end token) in the corpus is chosen, the tweet generation will stop. We have no criteria to choose the next token in this case.\n",
    "- If the next token is the end token and the at least 80% of `num_words` have been generated, the tweet generation will stop."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb4a5ae240ad52de"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def generate_tweets_from_bigrams(num_words: Optional[int] = 20, start_word: Optional[str] = \"<s>\") -> str:\n",
    "    current_word = start_word\n",
    "    tweet = [current_word]\n",
    "    for _ in range(num_words):\n",
    "        # get all bigrams that start with the current word\n",
    "        candidates = [bigram for bigram in bigrams_freq if bigram[0] == current_word]\n",
    "        if len(candidates) == 0:\n",
    "            # if there are no bigrams which start with current word we stop generating the tweet\n",
    "            break\n",
    "        \n",
    "        # get next bigram based on frequency, the higher the frequency the more likely the bigram will be chosen\n",
    "        next_bigram = random.choices(candidates, weights=[bigrams_freq[bigram] for bigram in candidates], k=1)[0]\n",
    "        next_word = next_bigram[1]\n",
    "        \n",
    "        if next_word == \"</s>\" and len(tweet) > num_words*0.8:\n",
    "            # if the next word is the end token and the tweet is at least 80% complete we stop generating the tweet\n",
    "            break\n",
    "        \n",
    "        tweet.append(next_word)\n",
    "        current_word = next_word\n",
    "    return join_tokens(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:00:48.611782200Z",
     "start_time": "2024-03-07T16:00:48.583157900Z"
    }
   },
   "id": "86e475ed8b4f8593"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To generate tweets from trigrams the following choices are made:\n",
    "- If the start words are not provided, the first word will be the start token and the second word will be chosen based on the frequency of the trigrams that start with the start token.\n",
    "- If a token that is never followed by another token (other than the end token) in the corpus is chosen, the tweet generation will stop. We have no criteria to choose the next token in this case.\n",
    "- If the next token is the end token and the at least 80% of num_words have been generated, the tweet generation will stop."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5045570b5d87c17"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def generate_tweets_from_trigrams(\n",
    "        num_words: Optional[int] = 20, \n",
    "        start_words: Optional[Tuple[str, str]] = (\"<s>\", None)) -> str:\n",
    "    \"\"\"\n",
    "    The function `generate_tweets_from_trigrams` generates a tweet based on trigrams. It takes two optional parameters:\n",
    "    :param Optional[int] num_words: which is maximum number of words that the generated tweet will have. The default value is 20. \n",
    "    :param Optional[Tuple[str,str]] start_words: which is a tuple of two strings that represent the first two words of the tweet. The default value is (\"<s>\", None) which means that the first word will be the start token and the second word will be chosen based on the frequency of the trigrams that start with the start token.\n",
    "    \n",
    "    :return: The function returns a string which represents the generated tweet.\n",
    "    \"\"\"\n",
    "    if start_words[1] is None:\n",
    "        # if the second word is not provided we choose it based on the frequency of the trigrams that start with the first word\n",
    "        candidates = [trigram for trigram in trigrams_freq if trigram[0] == start_words[0]]\n",
    "        next_trigram = random.choices(candidates, weights=[trigrams_freq[trigram] for trigram in candidates], k=1)[0]\n",
    "        start_words = (start_words[0], next_trigram[1])\n",
    "    current_words = start_words\n",
    "    tweet = list(current_words)\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        # get all trigrams that start with the current words\n",
    "        candidates = [trigram for trigram in trigrams_freq if trigram[:2] == current_words]\n",
    "        if len(candidates) == 0:\n",
    "            # if there are no trigrams which start with current words we stop generating the tweet\n",
    "            break\n",
    "        \n",
    "        # get next trigram based on frequency, the higher the frequency the more likely the trigram will be chosen\n",
    "        next_trigram = random.choices(candidates, weights=[trigrams_freq[trigram] for trigram in candidates], k=1)[0]\n",
    "        next_word = next_trigram[2]\n",
    "        \n",
    "        if next_word == \"</s>\" and len(tweet) > num_words*0.8:\n",
    "            # if the next word is the end token and the tweet is at least 80% complete we stop generating the tweet\n",
    "            break\n",
    "        \n",
    "        tweet.append(next_word)\n",
    "        current_words = (current_words[1], next_word)\n",
    "    return join_tokens(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:00:48.643775700Z",
     "start_time": "2024-03-07T16:00:48.601706300Z"
    }
   },
   "id": "4d9f88808ab13dc6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Test the tweet generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed94dadaa5c5da64"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@N_R_Mandela: //t.co/lJcHG0IHaM via @CheriJacobus. Plus $ 3.9 billion (or fired? I wear a loser\n"
     ]
    }
   ],
   "source": [
    "test_tweet_bigram = generate_tweets_from_bigrams(20)\n",
    "print(test_tweet_bigram)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:00:48.653776300Z",
     "start_time": "2024-03-07T16:00:48.614782100Z"
    }
   },
   "id": "de6a068d1df7b1db"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@pzarrella21: @realDonaldTrump: It should be out of the money raised by the people that got them there\n"
     ]
    }
   ],
   "source": [
    "test_tweet_trigram = generate_tweets_from_trigrams(20)\n",
    "print(test_tweet_trigram)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T16:00:48.661785Z",
     "start_time": "2024-03-07T16:00:48.630776400Z"
    }
   },
   "id": "8e8fbe551a3e0761"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c1017477c20f5b9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
