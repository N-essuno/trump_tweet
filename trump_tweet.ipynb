{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.002724Z",
     "start_time": "2024-02-27T13:56:45.987685Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional, Set\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the data and retrieve tweets tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a930147827f7723"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# first we need to clean the data\n",
    "# let's remove the \" from the tweets because some of them have \" at the start of the tweet but miss it at the end. This will cause the dataframe tweet column to be mixed with the following columns.\n",
    "with open('resources/tweets.csv', 'r', encoding=\"utf8\") as f:\n",
    "    tweets = f.readlines()\n",
    "    tweets = [tweet.replace('\"', '') for tweet in tweets]\n",
    "\n",
    "# write the cleaned tweets to a new file. Each row will contain a tweet cleaned text\n",
    "with open('resources/tweets_clean.csv', 'w', encoding=\"utf8\") as f:\n",
    "    for tweet in tweets:\n",
    "        f.write(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.034129Z",
     "start_time": "2024-02-27T13:56:46.014218Z"
    }
   },
   "id": "2979c8da9ea2510a",
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'LOSER', '!', 'https', ':', '//t.co/p5imhMJqS1', '</s>']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('resources/tweets_clean.csv')\n",
    "tweets_texts: List[str] = df['text'].tolist()\n",
    "tweets_tokens = [word_tokenize(tweet) for tweet in tweets_texts]\n",
    "# add start and end tokens to each tweet\n",
    "tweets_tokens = [['<s>'] + tweet + ['</s>'] for tweet in tweets_tokens]\n",
    "# merge all tokens into one list\n",
    "tokens = [token for tweet in tweets_tokens for token in tweet]\n",
    "\n",
    "print(tweets_tokens[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.144957Z",
     "start_time": "2024-02-27T13:56:46.037604Z"
    }
   },
   "id": "b82b1f3ee6df8b6d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# write tweets text on file\n",
    "with open('resources/tweets_tokens.txt', 'w', encoding=\"utf8\") as f:\n",
    "    for tweet in tweets_tokens:\n",
    "        f.write(' '.join(tweet) + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.160394Z",
     "start_time": "2024-02-27T13:56:46.147735Z"
    }
   },
   "id": "d5932677c4b8ebda",
   "execution_count": 131
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Generate n-grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e730e8b83e26fcf"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "bigrams = list(ngrams(tokens, 2))\n",
    "trigrams = list(ngrams(tokens, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.191148Z",
     "start_time": "2024-02-27T13:56:46.164956Z"
    }
   },
   "id": "305d6fd730cc1b7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Count n-grams frequencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "242ff5fd249f90c4"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "bigrams_freq = Counter(bigrams)\n",
    "trigrams_freq = Counter(trigrams)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.206624Z",
     "start_time": "2024-02-27T13:56:46.196155Z"
    }
   },
   "id": "b4df8f394825f916"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Generate tweets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28e8f453c9406b47"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "punctuation: Set = {\".\", \",\", \"!\", \"?\", \")\", \"]\", \"}\", \":\", \";\", \"'\", \"\\\"\", \"’\", \"‘\",\n",
    "               \"”\", \"–\", \"—\", \"…\", \"•\", \"·\", \"``\", \"''\"}\n",
    "\n",
    "def join_tokens(tweet_tokens: List[str]) -> str:\n",
    "    tweet_text:str = \"\"\n",
    "    skip_space = False\n",
    "    for token in tweet_tokens:\n",
    "        if token in punctuation:\n",
    "            tweet_text = tweet_text + token\n",
    "        elif token in (\"@\", \"(\", \"#\", \"“\"):\n",
    "            tweet_text += \" \" + token\n",
    "            skip_space = True\n",
    "        else:\n",
    "            if skip_space:\n",
    "                tweet_text += token\n",
    "                skip_space = False\n",
    "            else:\n",
    "                tweet_text += \" \" + token\n",
    "    return tweet_text.replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.222223Z",
     "start_time": "2024-02-27T13:56:46.210181Z"
    }
   },
   "id": "f41d6bcc896dddef",
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "def generate_tweets_from_bigrams(num_words: Optional[int] = 20, start_word: Optional[str] = \"<s>\") -> str:\n",
    "    current_word = start_word\n",
    "    tweet = [current_word]\n",
    "    for _ in range(num_words):\n",
    "        # get all bigrams that start with the current word\n",
    "        candidates = [bigram for bigram in bigrams_freq if bigram[0] == current_word]\n",
    "        if len(candidates) == 0:\n",
    "            # if there are no bigrams which start with current word we stop generating the tweet\n",
    "            break\n",
    "        # get next bigram based on frequency, the higher the frequency the more likely the bigram will be chosen\n",
    "        next_bigram = random.choices(candidates, weights=[bigrams_freq[bigram] for bigram in candidates], k=1)[0]\n",
    "        next_word = next_bigram[1]\n",
    "        if next_word == \"</s>\" and len(tweet) > num_words*0.8:\n",
    "            # if the next word is the end token and the tweet is at least 80% complete we stop generating the tweet\n",
    "            break\n",
    "        tweet.append(next_word)\n",
    "        current_word = next_word\n",
    "    return join_tokens(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.238271Z",
     "start_time": "2024-02-27T13:56:46.224491Z"
    }
   },
   "id": "86e475ed8b4f8593"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "def generate_tweets_from_trigrams(\n",
    "        num_words: Optional[int] = 20, \n",
    "        start_words: Optional[Tuple[str, str]] = (\"<s>\", None)) -> str:\n",
    "    \"\"\"\n",
    "    The function `generate_tweets_from_trigrams` generates a tweet based on trigrams. It takes two optional parameters:\n",
    "    :param Optional[int] num_words: which is maximum number of words that the generated tweet will have. The default value is 20. \n",
    "    :param Optional[Tuple[str,str]] start_words: which is a tuple of two strings that represent the first two words of the tweet. The default value is (\"<s>\", None) which means that the first word will be the start token and the second word will be chosen based on the frequency of the trigrams that start with the start token.\n",
    "    \n",
    "    :return: The function returns a string which represents the generated tweet.\n",
    "    \"\"\"\n",
    "    if start_words[1] is None:\n",
    "        # if the second word is not provided we choose it based on the frequency of the trigrams that start with the first word\n",
    "        candidates = [trigram for trigram in trigrams_freq if trigram[0] == start_words[0]]\n",
    "        next_trigram = random.choices(candidates, weights=[trigrams_freq[trigram] for trigram in candidates], k=1)[0]\n",
    "        start_words = (start_words[0], next_trigram[1])\n",
    "    current_words = start_words\n",
    "    tweet = list(current_words)\n",
    "    for _ in range(num_words):\n",
    "        # get all trigrams that start with the current words\n",
    "        candidates = [trigram for trigram in trigrams_freq if trigram[:2] == current_words]\n",
    "        if len(candidates) == 0:\n",
    "            # if there are no trigrams which start with current word we stop generating the tweet\n",
    "            break\n",
    "        # get next trigram based on frequency, the higher the frequency the more likely the trigram will be chosen\n",
    "        next_trigram = random.choices(candidates, weights=[trigrams_freq[trigram] for trigram in candidates], k=1)[0]\n",
    "        next_word = next_trigram[2]\n",
    "        if next_word == \"</s>\" and len(tweet) > num_words*0.8:\n",
    "            # if the next word is the end token and the tweet is at least 80% complete we stop generating the tweet\n",
    "            break\n",
    "        tweet.append(next_word)\n",
    "        current_words = (current_words[1], next_word)\n",
    "    return join_tokens(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.253499Z",
     "start_time": "2024-02-27T13:56:46.240709Z"
    }
   },
   "id": "4d9f88808ab13dc6"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@krauthammer is now dismissed or in the beginning have nothing but my friend @realDonaldTrump @BridgetGonzale3: //t.co/mbnmf8D8jI   @RepMattGaetz: @politico is a huge defeat by these clowns and yet Fox should be gone!   Why does n't believe in politics yet they still a very bright and @realDonaldTrump who have it loser!  . is firing sleepy eyes Chuck Todd in Vietnam) is the planet Donald Trump I notice you can still follow loser-boredom without being in months and Miss U.S.A. and winners for our true!   Mini Mike Bloomberg called many years along with 400 million dollars & amp; haters would never called his seat. Most people who fraudulently made up Trump from other reason they throw towards you keep tweeting the FBI. I agree - a bully a man I\n"
     ]
    }
   ],
   "source": [
    "test_tweet_bigram = generate_tweets_from_bigrams(150)\n",
    "print(test_tweet_bigram)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.354648Z",
     "start_time": "2024-02-27T13:56:46.259141Z"
    }
   },
   "id": "de6a068d1df7b1db"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every time I speak of the highest -and you all know it! Always respect FIGHTERS over overrated loser POLITITIANS!!!   Losers and haterseven you as low and dumb as you are jealous of his experience-unlike the haters and losers like @RepSwalwell (who got ZERO as presidential candidate before quitting) Pramila Jayapal David Cicilline and others who are Radical Left Story about Doral bedbugs but Bret Stephens is loaded up with a wonderful family. Michael is a stone cold loser who made up stories in order to sell the @UnionLeader. It 's a loser.   What my father really gave me is a stone cold loser who hates Michael a fine person with a wonderful family. Michael is a loser who deserves her comeuppance. @Lord_Sugar .... but you wouldn’ t. Like it or not it’ s a winner. EVERYONE knows that.Some LOSERS do n't) say I never called my friend @HowardStern a loser- he’ s phony lawsuit against Trump U was decimated by the RINO losers of the highest -and you all know it!   Sorry losers and haters never have @DannyZuker but he 's a loser.\n"
     ]
    }
   ],
   "source": [
    "test_tweet_trigram = generate_tweets_from_trigrams(250)\n",
    "print(test_tweet_trigram)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:56:46.606792Z",
     "start_time": "2024-02-27T13:56:46.358363Z"
    }
   },
   "id": "8e8fbe551a3e0761"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c1017477c20f5b9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
