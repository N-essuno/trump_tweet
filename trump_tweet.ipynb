{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:54:42.548696Z",
     "start_time": "2024-02-27T11:54:42.535402Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional, Set\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the data and retrieve tweets tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a930147827f7723"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# first we need to clean the data\n",
    "# let's remove the \" from the tweets because some of them have \" at the start of the tweet but miss it at the end. This will cause the dataframe tweet column to be mixed with the following columns.\n",
    "with open('resources/tweets.csv', 'r', encoding=\"utf8\") as f:\n",
    "    tweets = f.readlines()\n",
    "    tweets = [tweet.replace('\"', '') for tweet in tweets]\n",
    "\n",
    "# write the cleaned tweets to a new file. Each row will contain a tweet cleaned text\n",
    "with open('resources/tweets_clean.csv', 'w', encoding=\"utf8\") as f:\n",
    "    for tweet in tweets:\n",
    "        f.write(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:54:42.596025Z",
     "start_time": "2024-02-27T11:54:42.580085Z"
    }
   },
   "id": "2979c8da9ea2510a",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'LOSER', '!', 'https', ':', '//t.co/p5imhMJqS1', '</s>']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('resources/tweets_clean.csv')\n",
    "tweets_texts: List[str] = df['text'].tolist()\n",
    "tweets_tokens = [word_tokenize(tweet) for tweet in tweets_texts]\n",
    "# add start and end tokens to each tweet\n",
    "tweets_tokens = [['<s>'] + tweet + ['</s>'] for tweet in tweets_tokens]\n",
    "# merge all tokens into one list\n",
    "tokens = [token for tweet in tweets_tokens for token in tweet]\n",
    "\n",
    "print(tweets_tokens[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:54:42.696151Z",
     "start_time": "2024-02-27T11:54:42.602849Z"
    }
   },
   "id": "b82b1f3ee6df8b6d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# write tweeets text on file\n",
    "with open('resources/tweets_tokens.txt', 'w', encoding=\"utf8\") as f:\n",
    "    for tweet in tweets_tokens:\n",
    "        try:\n",
    "            f.write(' '.join(tweet) + '\\n')\n",
    "        except:\n",
    "            print(tweet)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:54:42.711190Z",
     "start_time": "2024-02-27T11:54:42.699848Z"
    }
   },
   "id": "d5932677c4b8ebda",
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Generate n-grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e730e8b83e26fcf"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "bigrams = list(ngrams(tokens, 2))\n",
    "trigrams = list(ngrams(tokens, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:54:42.726319Z",
     "start_time": "2024-02-27T11:54:42.715021Z"
    }
   },
   "id": "305d6fd730cc1b7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Count n-grams frequencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "242ff5fd249f90c4"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "bigrams_freq = Counter(bigrams)\n",
    "trigrams_freq = Counter(trigrams)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:54:42.741370Z",
     "start_time": "2024-02-27T11:54:42.729868Z"
    }
   },
   "id": "b4df8f394825f916"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Generate tweets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28e8f453c9406b47"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "punctuation: Set = {\".\", \",\", \"!\", \"?\", \")\", \"]\", \"}\", \":\", \";\", \"'\", \"\\\"\", \"’\", \"‘\",\n",
    "               \"“\", \"”\", \"–\", \"—\", \"…\", \"•\", \"·\", \"``\", \"''\"}\n",
    "\n",
    "def join_tokens(tokens: List[str]) -> str:\n",
    "    tweet_text:str = \"\"\n",
    "    skip_space = False\n",
    "    for token in tokens:\n",
    "        if token in punctuation:\n",
    "            tweet_text = tweet_text + token\n",
    "        elif token in (\"@\", \"(\", \"#\", \"“\"):\n",
    "            tweet_text += \" \" + token\n",
    "            skip_space = True\n",
    "        else:\n",
    "            if skip_space:\n",
    "                tweet_text += token\n",
    "                skip_space = False\n",
    "            else:\n",
    "                tweet_text += \" \" + token\n",
    "    return tweet_text.replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:54:42.756807Z",
     "start_time": "2024-02-27T11:54:42.742468Z"
    }
   },
   "id": "f41d6bcc896dddef",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "def generate_tweets_from_bigrams(num_words: Optional[int] = 20, start_word: Optional[str] = \"<s>\") -> str:\n",
    "    current_word = start_word\n",
    "    tweet = [current_word]\n",
    "    for _ in range(num_words):\n",
    "        # get all bigrams that start with the current word\n",
    "        candidates = [bigram for bigram in bigrams_freq if bigram[0] == current_word]\n",
    "        if len(candidates) == 0:\n",
    "            # if there are no bigrams which start with current word we stop generating the tweet\n",
    "            break\n",
    "        # get next bigram based on frequency, the higher the frequency the more likely the bigram will be chosen\n",
    "        next_bigram = random.choices(candidates, weights=[bigrams_freq[bigram] for bigram in candidates], k=1)[0]\n",
    "        next_word = next_bigram[1]\n",
    "        if next_word == \"</s>\" and len(tweet) > num_words*0.8:\n",
    "            # if the next word is the end token and the tweet is at least 80% complete we stop generating the tweet\n",
    "            break\n",
    "        tweet.append(next_word)\n",
    "        current_word = next_word\n",
    "    return join_tokens(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:54:42.772374Z",
     "start_time": "2024-02-27T11:54:42.758991Z"
    }
   },
   "id": "86e475ed8b4f8593"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "def generate_tweets_from_trigrams(\n",
    "        num_words: Optional[int] = 20, \n",
    "        start_words: Optional[Tuple[str, str]] = (\"<s>\", None)) -> str:\n",
    "    \"\"\"\n",
    "    The function `generate_tweets_from_trigrams` generates a tweet based on trigrams. It takes two optional parameters:\n",
    "    :param Optional[int] num_words: which is maximum number of words that the generated tweet will have. The default value is 20. \n",
    "    :param Optional[Tuple[str,str]] start_words: which is a tuple of two strings that represent the first two words of the tweet. The default value is (\"<s>\", None) which means that the first word will be the start token and the second word will be chosen based on the frequency of the trigrams that start with the start token.\n",
    "    \n",
    "    :return: The function returns a string which represents the generated tweet.\n",
    "    \"\"\"\n",
    "    if start_words[1] is None:\n",
    "        # if the second word is not provided we choose it based on the frequency of the trigrams that start with the first word\n",
    "        candidates = [trigram for trigram in trigrams_freq if trigram[0] == start_words[0]]\n",
    "        next_trigram = random.choices(candidates, weights=[trigrams_freq[trigram] for trigram in candidates], k=1)[0]\n",
    "        start_words = (start_words[0], next_trigram[1])\n",
    "    current_words = start_words\n",
    "    tweet = list(current_words)\n",
    "    for _ in range(num_words):\n",
    "        # get all trigrams that start with the current words\n",
    "        candidates = [trigram for trigram in trigrams_freq if trigram[:2] == current_words]\n",
    "        if len(candidates) == 0:\n",
    "            # if there are no trigrams which start with current word we stop generating the tweet\n",
    "            break\n",
    "        # get next trigram based on frequency, the higher the frequency the more likely the trigram will be chosen\n",
    "        next_trigram = random.choices(candidates, weights=[trigrams_freq[trigram] for trigram in candidates], k=1)[0]\n",
    "        next_word = next_trigram[2]\n",
    "        if next_word == \"</s>\" and len(tweet) > num_words*0.8:\n",
    "            # if the next word is the end token and the tweet is at least 80% complete we stop generating the tweet\n",
    "            break\n",
    "        tweet.append(next_word)\n",
    "        current_words = (current_words[1], next_word)\n",
    "    return join_tokens(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:54:42.788519Z",
     "start_time": "2024-02-27T11:54:42.774452Z"
    }
   },
   "id": "4d9f88808ab13dc6"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Morning_Joe. -- Robert T. Kiyosaki @DannyZuker Danny -- @KarlRove have been really bad!   Sorry losers!   The S & amp; prosper be a loser named“ wig. -- a protected 2nd Amendment biggest loser. Fiction!   @N_R_Mandela: Donald! https: There are setting records. Turned her lawyer he 's a total incompetent. You should look a glimmer of the act.   Thanks @KarlRove have not it more. Like @VMilaccio: @ec364: //t.co/rYsv90cnvs   ...  . Most people will fire himself-a total loser!   @MarkDRucker1: @jimbhoyx @KarlRove if they know I never a person reacts to look a dog by far beyond what the losing @FoxNews get it many times loser tonight by far the\n"
     ]
    }
   ],
   "source": [
    "test_tweet_bigram = generate_tweets_from_bigrams(150)\n",
    "print(test_tweet_bigram)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:54:57.214276Z",
     "start_time": "2024-02-27T11:54:57.142015Z"
    }
   },
   "id": "de6a068d1df7b1db"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It’ s campaign manager (?)lost big to“ O” & amp; losers must admit that unlike others I never called his wife’ s okay but why do n't even know how to win Texas on Tuesday. Cruz is a loser!   Great article by @jameshohmann @politico explaining why @MittRomney is a major loss for the loser of all time.   @MotAmazeBeGREAT: What separates the winners from the losers is how a person reacts to each new twist of fate. @Lord_Sugar .... but you wouldn’ t stop which is so good for the Republican Party. Hillary get on with your life and give it another try in three years!   What separates the winners from the losers is the talk of a total incompetent. He used Sloppy Steve Bannon who cried when he got fired!   They are strictly third rate.   @Bobzilla305: @realDonaldTrump And you 're lonely & amp; losers must be dealt with in a much tougher manner.The internet is their main recruitment tool which we must cut off & amp; protecting our great 2A they should love Sleepy Joe!\n"
     ]
    }
   ],
   "source": [
    "test_tweet_trigram = generate_tweets_from_trigrams(250)\n",
    "print(test_tweet_trigram)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:55:11.106704Z",
     "start_time": "2024-02-27T11:55:10.930870Z"
    }
   },
   "id": "8e8fbe551a3e0761"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c1017477c20f5b9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
