{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:19.139748Z",
     "start_time": "2024-02-27T14:32:19.118163Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from typing import List, Tuple, Optional, Set\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the data and retrieve tweets tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a930147827f7723"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we need to clean the data: let's remove the \" from the tweets because some of them have \" at the start of the tweet but miss it at the end. This will cause the dataframe tweet column to be mixed with the following columns."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f370ae307a3b6f78"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('resources/tweets.csv', 'r', encoding=\"utf8\") as f:\n",
    "    tweets = f.readlines()\n",
    "    tweets = [tweet.replace('\"', '') for tweet in tweets]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:19.186760Z",
     "start_time": "2024-02-27T14:32:19.166494Z"
    }
   },
   "id": "a4854a5eac1365f6",
   "execution_count": 224
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can retrieve the tweets tokens. We will use the `word_tokenize` function from the `nltk.tokenize` module to tokenize the tweets. We will also add the start and end tokens to each tweet and merge all tokens into one list."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c69a473a202a4306"
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'LOSER', '!', 'https', ':', '//t.co/p5imhMJqS1', '</s>']\n"
     ]
    }
   ],
   "source": [
    "tweet_texts = [tweet.split(\",\")[1] for tweet in tweets[1:]]\n",
    "tweets_tokens = [word_tokenize(tweet) for tweet in tweet_texts]\n",
    "# add start and end tokens to each tweet\n",
    "tweets_tokens = [['<s>'] + tweet + ['</s>'] for tweet in tweets_tokens]\n",
    "# merge all tokens into one list\n",
    "tokens = [token for tweet in tweets_tokens for token in tweet]\n",
    "\n",
    "print(tweets_tokens[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:19.322411Z",
     "start_time": "2024-02-27T14:32:19.190914Z"
    }
   },
   "id": "b82b1f3ee6df8b6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Generate n-grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e730e8b83e26fcf"
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "bigrams = list(ngrams(tokens, 2))\n",
    "trigrams = list(ngrams(tokens,3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:19.354284Z",
     "start_time": "2024-02-27T14:32:19.329015Z"
    }
   },
   "id": "305d6fd730cc1b7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Count n-grams frequencies\n",
    "\n",
    "For each n-gram we will use the `Counter` class from the `collections` module to count the frequency of each n-gram.\n",
    "Each n-gram will be stored in a dictionary where the key is the n-gram and the value is the frequency of the n-gram."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "242ff5fd249f90c4"
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "bigrams_freq = Counter(bigrams)\n",
    "trigrams_freq = Counter(trigrams)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:19.384969Z",
     "start_time": "2024-02-27T14:32:19.356434Z"
    }
   },
   "id": "b4df8f394825f916"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Generate tweets\n",
    "\n",
    "We will generate tweets using the bigrams and trigrams frequencies. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28e8f453c9406b47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we have the list of tokens for each tweet, we can join them in a human natural way (avoid spacing before punctuation mark, don't space before a @ or a # symbol)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2391b3a0d4baee89"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "punctuation: Set = {\".\", \",\", \"!\", \"?\", \")\", \"]\", \"}\", \":\", \";\", \"'\", \"\\\"\", \"’\", \"‘\",\n",
    "               \"”\", \"–\", \"—\", \"…\", \"•\", \"·\", \"``\", \"''\"}\n",
    "\n",
    "def join_tokens(tweet_tokens: List[str]) -> str:\n",
    "    tweet_text:str = \"\"\n",
    "    skip_space = False\n",
    "    for token in tweet_tokens:\n",
    "        if token in punctuation:\n",
    "            tweet_text = tweet_text + token\n",
    "        elif token in (\"@\", \"(\", \"#\", \"“\"):\n",
    "            tweet_text += \" \" + token\n",
    "            skip_space = True\n",
    "        else:\n",
    "            if skip_space:\n",
    "                tweet_text += token\n",
    "                skip_space = False\n",
    "            else:\n",
    "                tweet_text += \" \" + token\n",
    "    return tweet_text.replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:19.408094Z",
     "start_time": "2024-02-27T14:32:19.391146Z"
    }
   },
   "id": "f41d6bcc896dddef",
   "execution_count": 228
  },
  {
   "cell_type": "markdown",
   "source": [
    "To generate tweets from bigrams the following choices are made:\n",
    "- If the start word is not provided, the first word will be the start token.\n",
    "- If a token that is never followed by another token (other than the end token) in the corpus is chosen, the tweet generation will stop. We have no criteria to choose the next token in this case.\n",
    "- If the next token is the end token and the at least 80% of num_words have been generated, the tweet generation will stop."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb4a5ae240ad52de"
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "def generate_tweets_from_bigrams(num_words: Optional[int] = 20, start_word: Optional[str] = \"<s>\") -> str:\n",
    "    current_word = start_word\n",
    "    tweet = [current_word]\n",
    "    for _ in range(num_words):\n",
    "        # get all bigrams that start with the current word\n",
    "        candidates = [bigram for bigram in bigrams_freq if bigram[0] == current_word]\n",
    "        if len(candidates) == 0:\n",
    "            # if there are no bigrams which start with current word we stop generating the tweet\n",
    "            break\n",
    "        # get next bigram based on frequency, the higher the frequency the more likely the bigram will be chosen\n",
    "        next_bigram = random.choices(candidates, weights=[bigrams_freq[bigram] for bigram in candidates], k=1)[0]\n",
    "        next_word = next_bigram[1]\n",
    "        if next_word == \"</s>\" and len(tweet) > num_words*0.8:\n",
    "            # if the next word is the end token and the tweet is at least 80% complete we stop generating the tweet\n",
    "            break\n",
    "        tweet.append(next_word)\n",
    "        current_word = next_word\n",
    "    return join_tokens(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:19.423976Z",
     "start_time": "2024-02-27T14:32:19.411244Z"
    }
   },
   "id": "86e475ed8b4f8593"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To generate tweets from trigrams the following choices are made:\n",
    "- If the start words are not provided, the first word will be the start token and the second word will be chosen based on the frequency of the trigrams that start with the start token.\n",
    "- If a token that is never followed by another token (other than the end token) in the corpus is chosen, the tweet generation will stop. We have no criteria to choose the next token in this case.\n",
    "- If the next token is the end token and the at least 80% of num_words have been generated, the tweet generation will stop."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5045570b5d87c17"
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "def generate_tweets_from_trigrams(\n",
    "        num_words: Optional[int] = 20, \n",
    "        start_words: Optional[Tuple[str, str]] = (\"<s>\", None)) -> str:\n",
    "    \"\"\"\n",
    "    The function `generate_tweets_from_trigrams` generates a tweet based on trigrams. It takes two optional parameters:\n",
    "    :param Optional[int] num_words: which is maximum number of words that the generated tweet will have. The default value is 20. \n",
    "    :param Optional[Tuple[str,str]] start_words: which is a tuple of two strings that represent the first two words of the tweet. The default value is (\"<s>\", None) which means that the first word will be the start token and the second word will be chosen based on the frequency of the trigrams that start with the start token.\n",
    "    \n",
    "    :return: The function returns a string which represents the generated tweet.\n",
    "    \"\"\"\n",
    "    if start_words[1] is None:\n",
    "        # if the second word is not provided we choose it based on the frequency of the trigrams that start with the first word\n",
    "        candidates = [trigram for trigram in trigrams_freq if trigram[0] == start_words[0]]\n",
    "        next_trigram = random.choices(candidates, weights=[trigrams_freq[trigram] for trigram in candidates], k=1)[0]\n",
    "        start_words = (start_words[0], next_trigram[1])\n",
    "    current_words = start_words\n",
    "    tweet = list(current_words)\n",
    "    for _ in range(num_words):\n",
    "        # get all trigrams that start with the current words\n",
    "        candidates = [trigram for trigram in trigrams_freq if trigram[:2] == current_words]\n",
    "        if len(candidates) == 0:\n",
    "            # if there are no trigrams which start with current word we stop generating the tweet\n",
    "            break\n",
    "        # get next trigram based on frequency, the higher the frequency the more likely the trigram will be chosen\n",
    "        next_trigram = random.choices(candidates, weights=[trigrams_freq[trigram] for trigram in candidates], k=1)[0]\n",
    "        next_word = next_trigram[2]\n",
    "        if next_word == \"</s>\" and len(tweet) > num_words*0.8:\n",
    "            # if the next word is the end token and the tweet is at least 80% complete we stop generating the tweet\n",
    "            break\n",
    "        tweet.append(next_word)\n",
    "        current_words = (current_words[1], next_word)\n",
    "    return join_tokens(tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:19.439901Z",
     "start_time": "2024-02-27T14:32:19.426245Z"
    }
   },
   "id": "4d9f88808ab13dc6"
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... get rid of millions of you -- You mean the haters & amp; husband and you destroy your face.Not haterslosers!  . You should be fine person reacts to run for Evan “wig.” -- perhaps because she was under their ratings loser CNN can only tear down the losers is a winner!   @Bet22325450ste: “O” http: //t.co/sgiETvdUqi   @politico explaining why would like picking on even care anymore. @TheTinaBeast’ t stop what Sean do n't think of the coolest guy who doesn’ So many people for the same old losers is a real positive in a loser for the 2016  . Just watched a strong and Losers!\n"
     ]
    }
   ],
   "source": [
    "test_tweet_bigram = generate_tweets_from_bigrams(150)\n",
    "print(test_tweet_bigram)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:19.540556Z",
     "start_time": "2024-02-27T14:32:19.442421Z"
    }
   },
   "id": "de6a068d1df7b1db"
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Lumberportal: @DannyZuker Danny -- You 're never a loser!   @REAPEROFTRUTH: @realDonaldTrump: It should be out of trouble even if ....  . @NRO Not much is as dead or irrelevant as National Review thanks to guidance of Goldberg a total loser for Democrats. The interest in and importance of these losers just ca n't win!   Mini Mike Bloomberg. His “political” consultants took him for a ride. $ 700 million washed down the Government lets them out of trouble even if ....   .... because they don’ t care about 252 new Federal Judges 2 great Supreme Court Justices a rebuilt military a protected 2nd Amendment biggest EVER Tax & amp; husband from hell!   .... must stay strong and fight back with her help didn’ t envision this. You should just ignore their false reporting. But there are many) a truly happy and enjoyable Memorial Day!   @rodmonium91: @seanhannity @realDonaldTrump The biggest loser tonight by far the most corrupt & amp; Trade are losers.\n"
     ]
    }
   ],
   "source": [
    "test_tweet_trigram = generate_tweets_from_trigrams(250)\n",
    "print(test_tweet_trigram)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:19.813072Z",
     "start_time": "2024-02-27T14:32:19.543955Z"
    }
   },
   "id": "8e8fbe551a3e0761"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c1017477c20f5b9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
